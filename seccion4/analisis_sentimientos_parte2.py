# ROB: igual que parte1 pero al final meto chain.batch para varias entradas en paralelo
from langchain_core.runnables import RunnableLambda, RunnableParallel
from langchain_openai import ChatOpenAI
import json

# Configuración del modelo
llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)
# Preprocesador: limpia espacios y limita a 500 caracteres
def preprocess_text(text):
    """Limpia el texto eliminando espacios extras y limitando longitud"""
    return text.strip()[:500]
preprocessor = RunnableLambda(preprocess_text)
# Generación de resumen
def generate_summary(text):
    """Genera un resumen conciso del texto"""
    prompt = f"Resume en una sola oración: {text}"
    response = llm.invoke(prompt)
    return response.content
summary_brach = RunnableLambda(generate_summary)
# Análiss de sentimiento con formato JSON
def analyze_sentiment(text):
    """Analiza el sentimiento y devuelve resultado estructurado"""
    prompt = f"""Analiza el sentimiento del siguiente texto.
    Responde ÚNICAMENTE en formato JSON válido:
    {{"sentimiento": "positivo|negativo|neutro", "razon": "justificación breve"}}

    Texto: {text}"""
    response = llm.invoke(prompt)
    try:
        return json.loads(response.content)
    except json.JSONDecodeError:
        return {"sentimiento": "neutro", "razon": "Error en análisis"}
sentiment_branch = RunnableLambda(analyze_sentiment)
# Combinación de resultados
def merge_results(data):
    """Combina los resultados de ambas ramas en un formato unificado"""
    return {
        "resumen": data["resumen"],
        "sentimiento": data["sentimiento_data"]["sentimiento"],
        "razon": data["sentimiento_data"]["razon"]
    }
merger = RunnableLambda(merge_results)
parallel_analysis = RunnableParallel({
    "resumen": summary_brach,
    "sentimiento_data": sentiment_branch
})
# Cadena completa
chain = preprocessor | parallel_analysis | merger

############## ROB: EJECUTAR EL LLM CON MUCHAS ENTRADAS EN PARALELO ########## -> 3 tarda lo mismo que 1
reviews_batch = [ # lista que se mete en el chain.batch como variable al chain completo
    "Excelente producto, muy satisfecho con la compra",
    "Terrible calidad, no lo recomiendo para nada",
    "Está bien, cumple su función básica pero nada especial"
]
# ROB: USA CHAIN.BATCH para ejecutar en paralelo (.batch en lugar de .invoke)
resultado_batch = chain.batch(reviews_batch)
print(resultado_batch)